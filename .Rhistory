summary(reg)
b = inv(t(x)%*%x)%*%t(x)%*%y
b
reg = lm(y ~x1 + x2 - 1)
summary(reg)
b
137-133.89
133.189-138.5
-133.189+138.5
(-133.189+138.5)*5
(-133.189+138.99)*5
(16-4.8)/4.8
4.8/16
0.7*16
16-11.2
4.8*0.7
4.8*1.7
16/4.8
25.5/669.45
100*(25.5/669.45)
install.packages(sn)
install.packages('sn')
---
title: "Untitled"
output: html_document
---
---
title: "Untitled"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## R Markdown
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r cars}
summary(cars)
```
## Including Plots
You can also embed plots, for example:
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
plot(pressure)
plot(pressure)
```{r cars}
```{r cars}
library(tseries)
library(timeSeries)
library(forecast)   # auto.arima
library(tseries)
library(timeSeries)
library(forecast)   # auto.arima
library(tseries)
library(timeSeries)
#library(forecast)   # auto.arima
library(quantmod)
library(fGarch)
library(mFilter)
library(GetBCBData)   # get Bacen data
ibov = getSymbols('^BVSP', src='yahoo', from= '2007-01-01', auto.assign = F)[,4]
colnames(ibov)= c('ibov')
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
head(ibov)
plot(ibov)
ret = diff(log(ibov))
colnames(ret) = c('ret')
ret = ret[is.na(ret)==F]  # Drop na to work
par(mfrow=c(2,1))
plot(ret)
acf(ret)   # There isn't autocorrelation in returns. So isn't possible predict ret
par(mfrow=c(1,2))
plot(ret)
acf(ret)   # There isn't autocorrelation in returns. So isn't possible predict ret
par(mfrow=c(1,2))
plot(ret, main='Evolução dos retornos do IBOV')
acf(ret)   # There isn't autocorrelation in returns. So isn't possible predict ret
par(mfrow=c(2,1))
plot(ret^2)
acf(ret^2)   # In squares of returns there is autocorrelation
par(mfrow=c(1,2))
plot(ret^2, main= 'Evolução do quadrado dos retornos do IBOV')
acf(ret^2)   # In squares of returns there is autocorrelation
basicStats(ibov)
basicStats(ret)
basicStats(ibov)
basicStats(ret)
for (i in 1:5) {
print(ArchTest(x = ret, lags = i))
}
library(tseries)
library(timeSeries)
library(forecast)   # auto.arima
library(quantmod)
library(fGarch)
library(mFilter)
library(GetBCBData)   # get Bacen data
for (i in 1:5) {
print(ArchTest(x = ret, lags = i))
}
library(forecast)   # auto.arima
install.packages(forecast)
install.packages('forecast')
library(forecast)   # auto.arima
install.packages('glue')
library(glue)
library(forecast)   # auto.arima
library(fGarch)
library(mFilter)
library(GetBCBData)   # get Bacen data
library(quantmod)
library(tseries)
library(timeSeries)
for (i in 1:5) {
print(ArchTest(x = ret, lags = i))
}
for (i in 1:5) {
print(archTest(x = ret, lags = i))
}
for (i in 1:5) {
print(ArchTest(x = ret, lags = i))
}
for (i in 1:5) {
print(arch.test(x = ret, lags = i))
}
garch1 = garchFit(formula = ~garch(1,1),
data = ret)
garch1 = garchFit(formula = ~garch(1,1),
data = ret)
garch1 = garchFit(formula = ~garch(1,1),data = ret)
summary(garch1)
vol = garch1@sigma.t
vol = as.xts(vol, order.by = data)
vol = garch1@sigma.t
vol = as.xts(vol, order.by = data)
vol = garch1@sigma.t
vol = as.xts(vol, order.by = data)
data = index(ret)
vol = garch1@sigma.t
vol = as.xts(vol, order.by = data)
data = index(ret)
vol = garch1@sigma.t
vol = as.xts(vol, order.by = data)
par(mfrow=c(2, 2))
plot(ibov, main='Evolution of IBOV')
plot(ret, main='Evolution of IBOV returns')
plot(ret^2, main='Evolution of square of IBOV returns')
plot(vol, main= 'Volatility of IBOV returns by GARCH(1,1)')
library(rugarch)
spec = ugarchspec()
spec
ugarchfit(variance.model = )
#ugarchfit(variance.model = )
spec1 = ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(1,1)),
mean.model=list(armaOrder=c(1,0), include.mean=TRUE),
distribution.model="norm")
garch2 = ugarchfit(spec = spec1, data= ret)
garch2
pred2 = ugarchforecast(garch2, n.ahead = 5)
plot(pred2, type='l')
pred2 = ugarchforecast(garch2, n.ahead = 5)
pred2 = pred2@forecast$sigmaFor
plot(pred2, type='l')
pred2 = ugarchforecast(garch2, n.ahead = 5)
plot(pred2, type='l')
ibov = getSymbols('^BVSP', src='yahoo', from= '2007-01-01', auto.assign = F)[,4]
colnames(ibov)= c('ibov')
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
head(ibov)
head(ibov)
par(mfrow=c(3,1))
plot(ret^2)
acf(ret^2)   # In squares of returns there is autocorrelation
pacf(ret^2)
plot(ret, main='Evolution of IBOV returns')
plot(ret, main='Evolution of IBOV returns')
plot(ibov, main='Evolution of \n IBOV')
garch1 = garchFit(formula = ~garch(1,1),
data = ret)
garch1 = garchFit(formula = ~garch(1,1),
data = ret);
quiet(garch1 = garchFit(formula = ~garch(1,1),
data = ret))
library(ddpcr)
install.packages(ddpcr)
install.packages('ddpcr')
library(ddpcr)
quiet(garch1 = garchFit(formula = ~garch(1,1),
data = ret))
garch1 = quiet(garchFit(formula = ~garch(1,1),
data = ret))
garch1
garch1 = garchFit(formula = ~garch(1,1),
data = ret)
knitr::opts_chunk$set(echo = TRUE)
library(tseries)
library(timeSeries)
library(quantmod)
library(fGarch)
library(mFilter)
ibov = getSymbols('^BVSP', src='yahoo', from= '2007-01-01', auto.assign = F)[,4]
colnames(ibov)= c('ibov')
ibov = ibov[is.na(ibov)==F]   # elimina os na's da amostra
head(ibov)
plot(ibov)
ret = diff(log(ibov))
colnames(ret) = c('ret')
ret = ret[is.na(ret)==F]  # Drop na to work
par(mfrow=c(2,1))
plot(ret, main='Evolução dos retornos do IBOV')
acf(ret)   # There isn't autocorrelation in returns. So isn't possible predict ret
par(mfrow=c(2,1))
plot(ret^2, main= 'Evolução do quadrado dos retornos do IBOV')
acf(ret^2)   # In squares of returns there is autocorrelation
basicStats(ret)
basicStats(ibov)
garch1 = garchFit(formula = ~garch(1,1),data = ret)
summary(garch1)
data = index(ret)
vol = garch1@sigma.t
vol = as.xts(vol, order.by = data)
par(mfrow=c(2, 2))
plot(ibov, main='Evolution of IBOV')
plot(ret, main='Evolution of IBOV returns')
plot(ret^2, main='Evolution of square \n of IBOV returns')
plot(vol, main= 'Volatility of IBOV \n returns by GARCH(1,1)')
# Libraries
library(tseries)
library(timeSeries)
library(forecast)   # auto.arima
library(quantmod)
library(fGarch)
library(mFilter)
library(GetBCBData)   # get Bacen data
ibov = getSymbols('^BVSP', src='yahoo', from= '2007-01-01', auto.assign = F)[,4]
colnames(ibov)= c('ibov')
ibov = ibov[is.na(ibov)==F]
ret = diff(log(ibov))
colnames(ret) = c('ret')
ret = ret[is.na(ret)==F]  # Drop na to work
garch1 = garchFit(formula = ~garch(1,1),
data = ret)
summary(garch1)
mean(ret^2)
arima(ret^2, order = c(0,0,0))
mean(ret^2)
source('~/combination_credit.R', echo=TRUE)
rm(garch1)
rm(list=c('ibov', 'ret'))
nn = readRDS(rf)
nn = readRDS('rf')
nn = readRDS('rf.RDS')
rf = readRDS('rf.RDS')
nn = readRDS('NN.RDS')
prev_rf = as.numeric(trimws(prev_rf))
prev_rf = (rf, newdata= df[ ,-4])
prev_rf = predict(rf, newdata= df[ ,-4])
prev_rf = as.numeric(trimws(prev_rf))
prev_nn = predict(nn, newdata= as.h2o(df[ ,-4]))
library(h2o)
prev_nn = predict(nn, newdata= as.h2o(df[ ,-4]))
h2o.init()
prev_nn = predict(nn, newdata= as.h2o(df[ ,-4]))
prev_nn[1]
prev_nn[3]
prev_nn[5]
prev_nn[1, 3]
View(prev_nn)
prev_nn$V1[1:4]
prev_nn$V1
View(prev_nn)
prev_nn$V1
prev_nn@V1
prev_nn = as.numeric(trimws(prev_nn))
View(prev_nn)
prev_nn[3]
prev_nn[3:5]
prev_nn[1:5]
prev_nn[1:20]
prev_rf = predict(rf, newdata= df[1,-4])
prev_rf = as.numeric(trimws(prev_rf))
prev_nn = predict(nn, newdata= as.h2o(df[1 ,-4]))
prev_nn = as.numeric(as.vector(prev_nn))
c0 = 0
c1 = 0
if ( prev_rf==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if ( prev_nn==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if (c1 > c0){
print('Classe 1')
}else if(c0 == c1){
print('Os classificadores encontraram resultados diferentes')
}else{
print('Classe 0')
}
prev_rf = predict(rf, newdata= df[,-4])
prev_rf = as.numeric(trimws(prev_rf))
prev_nn = predict(nn, newdata= as.h2o(df[1 ,-4]))
prev_nn = as.numeric(as.vector(prev_nn))
prev_nn = predict(nn, newdata= as.h2o(df[ ,-4]))
prev_nn = as.numeric(as.vector(prev_nn))
c0 = 0
c1 = 0
for(i in 1:length(prev_nn) ){
if ( prev_rf==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if ( prev_nn==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if (c1 > c0){
print('Classe 1')
}else if(c0 == c1){
print('Os classificadores encontraram resultados diferentes')
}else{
print('Classe 0')
}
}
for(i in 1:length(prev_nn) ){
c0 = 0
c1 = 0
if ( prev_rf==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if ( prev_nn==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if (c1 > c0){
print('Classe 1')
}else if(c0 == c1){
print('Os classificadores encontraram resultados diferentes')
}else{
print('Classe 0')
}
}
for(i in 1:length(prev_nn) ){
c0 = 0
c1 = 0
if ( prev_rf[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if ( prev_nn[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if (c1 > c0){
print('Classe 1')
}else if(c0 == c1){
print('Os classificadores encontraram resultados diferentes')
}else{
print('Classe 0')
}
}
c0_a = 0
cdif = 0
c1_a = 0
for(i in 1:length(prev_nn) ){
c0 = 0
c1 = 0
if ( prev_rf[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if ( prev_nn[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if (c1 > c0){
print('Classe 1')
c1_a = c1_a + 1
}else if(c0 == c1){
print('Os classificadores encontraram resultados diferentes')
c_dif = c_dif + 1
}else{
print('Classe 0')
c0_a = c0_a + 1
}
}
c0_a = 0
c_dif = 0
c1_a = 0
for(i in 1:length(prev_nn) ){
c0 = 0
c1 = 0
if ( prev_rf[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if ( prev_nn[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if (c1 > c0){
print('Classe 1')
c1_a = c1_a + 1
}else if(c0 == c1){
print('Os classificadores encontraram resultados diferentes')
c_dif = c_dif + 1
}else{
print('Classe 0')
c0_a = c0_a + 1
}
}
cat('Os dois classificadores classificaram como c1' c1_a)
cat('Os dois classificadores classificaram como c1', c1_a)
cat('Os dois classificadores classificaram como c1', c1_a, 'registros')
cat('Os dois classificadores chegaram a resultados direntes em', c_dif, 'registros')
class = c()
class[1]=2
c0_a = 0
c_dif = 0
c1_a = 0
class = c()
for(i in 1:length(prev_nn) ){
c0 = 0
c1 = 0
if ( prev_rf[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if ( prev_nn[i]==0){
c0 = c0 + 1
}else {
c1 = c1 + 1
}
if (c1 > c0){
print('Classe 1')
c1_a = c1_a + 1
class[i] = 1
}else if(c0 == c1){
print('Os classificadores encontraram resultados diferentes')
c_dif = c_dif + 1
class[i] = prev_nn[i]
}else{
print('Classe 0')
c0_a = c0_a + 1
class[i] = 0
}
}
cat('Os dois classificadores classificaram como c1', c1_a, 'registros')
cat('Os dois classificadores classificaram como c0', c0_a, 'registros')
cat('Os dois classificadores chegaram a resultados direntes em', c_dif, 'registros')
summary(class)
table(class)
prob_rf = predict(rf, newdata=df[1,-4], type='prob')
View(prob_rf)
prob_rf = predict(rf, newdata=df[,-4], type='prob')
View(nn)
View(prob_rf)
conf_rf = max(prob_rf)
conf_rf = max(prob_rf[])
conf_rf = max(prob_rf$`0`, prob_rf$`1`)
for (i in 1:length(prob_rf)){
conf_rf[i] = max(prob_rf$`0`[i], prob_rf$`1`[i])
}
length(prob_rf)
for (i in 1:2000){
conf_rf[i] = max(prob_rf$`0`[i], prob_rf$`1`[i])
}
View(conf_rf)
prob_nn = predict(nn, newdata=as.h2o(df[,-4]), type='prob')
View(prob_nn)
for (i in 1:2000){
conf_nn[i] = max(prob_nn$`0`[i], prob_nn$`1`[i])
}
for (i in 1:2000){
conf_nn[i] = max(prob_nn$`0`[i], prob_nn$`1`[i])
}
conf_nn= c()
for (i in 1:2000){
conf_nn[i] = max(prob_nn$`0`[i], prob_nn$`1`[i])
}
View(conf_nn)
confint(conf_rf, 0.95)
confint(conf_rf, mean, 0.95)
confint(conf_rf, parm = 'mean',  0.95)
summary(conf_rf)
t.test(conf_rf)

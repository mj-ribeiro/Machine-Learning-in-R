e_t = e_t + e
for (j in length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
#return(pes)
}
neural()
#### Neural network
length(s)
for(i in length(s)){
print(i)
}
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
print(s_cal)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
#return(pes)
}
neural()
for(i in 1:length(s)){
print(i)
}
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
print(s_cal)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
#return(pes)
}
neural()
neural()
neural()
step(ent[1, ]%*%pes)
step(ent[2, ]%*%pes)
step(ent[-2, ]%*%pes)
step(-1)
ent[2, ]%*%pes
ent[1, ]%*%pes
step = function(soma){
if (soma>=1) {
return(1)
}else{
return(0)
}
}
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
print(s_cal)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
#return(pes)
}
neural()
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
print(s_cal)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
return(pes)
}
neural()
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
print(s_cal)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
print(pes)
}
neural()
print('olá')
print('olá', 4)
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
print(s_cal)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
print('Os pesos são', pes)
}
neural()
print('pesos', pes)
print('pesos' pes)
print('pesos', 3)
cat('pesos', 3)
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
cat('Os pesos são', pes)
}
neural()
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
}
}
}
cat('Os pesos são':, pes)
}
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
print(e_t)
}
}
}
cat('Os pesos são':, pes)
}
neural = function(){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
}
}
}
cat('Os pesos são:', pes)
}
neural()
#***************************************************************************
#                          Neural Network
#****************************************************************************
e1 = c(0, 0)
e2 = c(0, 1)
e3 = c(1, 0)
e4 = c(1, 1)
ent = rbind(e1, e2, e3, e4)
pes = c(0, 0)
s = c(0 , 0, 0, 1)
step = function(soma){
if (soma>=1) {
return(1)
}else{
return(0)
}
}
#### Neural network
neural = function(apr){
e_t = 1
while(e_t !=0){
e_t = 0
for (i in 1:length(s)){
s_cal = step(ent[i, ]%*%pes)
e = abs(s[i] - s_cal)
e_t = e_t + e
for (j in 1:length(pes)) {
pes[j] = pes[j] + apr * ent[i, j] * e
}
}
}
cat('Os pesos são:', pes)
}
neural(0.1)
neural(0.2)
neural(0.3)
neural(1)
neural(0.2)
neural(0.1)
121 - 74
47*12.7
11.44*60 + 12.35*61 - 47*12.7 +74*12.55
-11.44*60 - 12.35*61 + 47*12.7 + 74*12.55
-8.39 *99 + 8.49*99
-7.94*100 + 8.12*100
-8.50*100 + 9.3*100
-17.79*6 + 19.5*6
85+85+9.9+18+10.26
-8.12*100+8.78*100
install.packages(ctv)
install.packages('ctv')
install.packages('moments')
x1 = c(2, 1, 5, 7, 8, 0, 2, 1)
x1 = c(2, 1, 5, 7, 8, 0, 2, 1)
l = 0.5
x = cbind(x1, x2)
x = cbind(x1, x2)
x2 = c(11, 2, 4, 5, 78, 1, 2, 9)
x2 = c(11, 2, 4, 5, 78, 1, 2, 9)
x2 = c(11, 2, 4, 5, 78, 1, 2, 9)
x = cbind(x1, x2)
l = 0.5
y = c(1, 5, 2, 3, 7, 32, 2, 0)
b = t(t(x)%*%x)%*%t(x)%*%
b = t(t(x)%*%x)%*%t(x)%*%y
b = t(t(x)%*%x)%*%t(x)%*%y
b
b = inv(t(x)%*%x)%*%t(x)%*%y
install.packages("matlib")
library(matlib)
b = inv(t(x)%*%x)%*%t(x)%*%y
b
b = inv(t(x)%*%x + l )%*%t(x)%*%y
b
b = inv(t(x)%*%x + 1000 )%*%t(x)%*%y
b
reg = lm(y ~x1 + x2)
summary(reg)
b = inv(t(x)%*%x)%*%t(x)%*%y
b
reg = lm(y ~x1 + x2 - 1)
summary(reg)
b
137-133.89
133.189-138.5
-133.189+138.5
(-133.189+138.5)*5
(-133.189+138.99)*5
(16-4.8)/4.8
4.8/16
0.7*16
16-11.2
4.8*0.7
4.8*1.7
16/4.8
25.5/669.45
100*(25.5/669.45)
setwd("D:/Git projects/ML in R")
setwd("D:/Git projects/ML in R")
#---- algorithm
#---- algorithm
source('D:/Git projects/ML in R/neural_networks_aplied_credit.R', echo=TRUE)
library(h20)
library(h2o)
library('h2o')
#---- algorithm
install.packages('h2o')
library('h2o')
h2o.init(nthreads = -1)
h2o.init(nthreads = 1)
h2o.init(nthreads = -1)
h2o.init(nthreads = 1)
clas = h20.deeplearning(y = 'default',
training_frame = as.h20(df_train),
activation = 'Rectifier',
hidden= c(100),
epochs = 1000)
library('h2o')
clas = h2o.deeplearning(y = 'default',
training_frame = as.h20(df_train),
activation = 'Rectifier',
hidden= c(100),
epochs = 1000)
clas = h2o.deeplearning(y = 'default',
training_frame = as.h2o(df_train),
activation = 'Rectifier',
hidden= c(100),
epochs = 1000)
library('h2o')
h2o.init(nthreads = -1)
clas = h2o.deeplearning(y = 'default',
training_frame = as.h2o(df_train),
activation = 'Rectifier',
hidden= c(100),
epochs = 1000)
summary(clas)
prev = h2o.predict(clas, newdata=as.h2o(df_test[-4]))
prev
View(df_test)
View(df_test)
prev = as.vector(prev)
prev
View(prev)
conf_matrix = table(df_test[ ,4], prev)
prev = h2o.predict(clas, newdata=as.h2o(df_test[-4]))
View(prev)
prev = (prev > 0.5)
View(df_train)
View(prev)
View(prev)
prev
prev = h2o.predict(clas, newdata=as.h2o(df_test[-4]))
prev
prev$predict
prev = prev$predict
prev = as.vector(prev)
conf_matrix = table(df_test[ ,4], prev)
conf_matrix
confusionMatrix(conf_matrix)
#***********************************************************************************
#                             Neural Networks
#***********************************************************************************
plotnet()
#***********************************************************************************
#                             Neural Networks
#***********************************************************************************
library(rpart)
library(rpart.plot)
library(fBasics)
library(caTools)  # split data
library(caret)    #provide metrics for confusion matrix
#-------------- Read data
base = read.csv('census.csv')
base$X = NULL
attach(base)
#------------------ CATEGORIZING DATA
base$sex = factor(base$sex, levels = unique(base$sex), labels = c(1, 0))
base$workclass = factor(base$workclass, levels = c(' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$education = factor(base$education, levels = c(' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16))
base$marital.status = factor(base$marital.status, levels = c(' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed'), labels = c(1, 2, 3, 4, 5, 6, 7))
base$occupation = factor(base$occupation, levels = c(' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
base$relationship = factor(base$relationship, levels = c(' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife'), labels = c(1, 2, 3, 4, 5, 6))
base$race = factor(base$race, levels = c(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), labels = c(1, 2, 3, 4, 5))
base$native.country = factor(base$native.country, levels = c(' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41))
base$income = factor(base$income, levels = c(' <=50K', ' >50K'), labels = c(0, 1))
#---------------- SCALING
base[ , 1] = scale(base[ , 1])
base[ , 3] = scale(base[ , 3])
base[ , 5] = scale(base[ , 5])
base[ , 11:13] = scale(base[ , 11:13])
#----------------------- TRAIN AND TEST
set.seed(1)
div = sample.split(base$income, SplitRatio = 0.85)
base_train = subset(base, div == T)
base_test = subset(base, div == F)
# ------------ Algorithm
library(h2o)
h2o.init()
base$sex = factor(base$sex, levels = unique(base$sex), labels = c(1, 0)))
base$workclass = as.numeric(factor(base$workclass, levels = c(' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', ' State-gov', ' Without-pay'), labels = c(1, 2, 3, 4, 5, 6, 7)))
base$education = as.numeric(factor(base$education, levels = c(' 10th', ' 11th', ' 12th', ' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th', ' Assoc-acdm', ' Assoc-voc', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)))
base$marital.status = as.numeric(factor(base$marital.status, levels = c(' Divorced', ' Married-AF-spouse', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed'), labels = c(1, 2, 3, 4, 5, 6, 7)))
base$occupation = as.numeric(factor(base$occupation, levels = c(' Adm-clerical', ' Armed-Forces', ' Craft-repair', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)))
base$relationship = as.numeric(factor(base$relationship, levels = c(' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife'), labels = c(1, 2, 3, 4, 5, 6)))
base$race = as.numeric(factor(base$race, levels = c(' Amer-Indian-Eskimo', ' Asian-Pac-Islander', ' Black', ' Other', ' White'), labels = c(1, 2, 3, 4, 5)))
base$native.country = as.numeric(factor(base$native.country, levels = c(' Cambodia', ' Canada', ' China', ' Columbia', ' Cuba', ' Dominican-Republic', ' Ecuador', ' El-Salvador', ' England', ' France', ' Germany', ' Greece', ' Guatemala', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' India', ' Iran', ' Ireland', ' Italy', ' Jamaica', ' Japan', ' Laos', ' Mexico', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Philippines', ' Poland', ' Portugal', ' Puerto-Rico', ' Scotland', ' South', ' Taiwan', ' Thailand', ' Trinadad&Tobago', ' United-States', ' Vietnam', ' Yugoslavia'), labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41)))
base$income = as.numeric(factor(base$income, levels = c(' <=50K', ' >50K'), labels = c(0, 1)))
#---------------- SCALING
base[ , 1] = scale(base[ , 1])
base[ , 3] = scale(base[ , 3])
base[ , 5] = scale(base[ , 5])
base[ , 11:13] = scale(base[ , 11:13])
#----------------------- TRAIN AND TEST
set.seed(1)
div = sample.split(base$income, SplitRatio = 0.85)
base_train = subset(base, div == T)
base_test = subset(base, div == F)
# ------------ Algorithm
library(h2o)
h2o.init()
source('D:/Git projects/ML in R/neural_networks_aplied_census.R', echo=TRUE)
base[ , 1] = scale(base[ , 1])
base[ , 3] = scale(base[ , 3])
base[ , 5] = scale(base[ , 5])
base[ , 11:13] = scale(base[ , 11:13])
#----------------------- TRAIN AND TEST
set.seed(1)
div = sample.split(base$income, SplitRatio = 0.85)
base_train = subset(base, div == T)
base_test = subset(base, div == F)
# ------------ Algorithm
library(h2o)
h2o.init()
source('D:/Git projects/ML in R/neural_networks_aplied_census.R', echo=TRUE)
clas = h2o.deeplearning(y= 'income',
training_frame = as.h2o(base_train),
hidden = c(100),
epochs = 1000)
prev = h2o.predict(clas, newdata=as.h2o(base_test[, -15]))
prev
prev = as.vector(prev)
prev = h2o.predict(clas, newdata=as.h2o(base_test[, -15]))
prev = prev$predict
prev = as.vector(prev)
conf_matrix = table(base_test[,15], prev)
conf_matrix
confusionMatrix(conf_matrix)
clas = h2o.deeplearning(y= 'income',
training_frame = as.h2o(base_train),
hidden = c(100, 100),
epochs = 1000)
prev = h2o.predict(clas, newdata=as.h2o(base_test[, -15]))
prev = prev$predict
prev = as.vector(prev)
#------------- Confusion Matrix
conf_matrix = table(base_test[,15], prev)
conf_matrix
confusionMatrix(conf_matrix)
clas = h2o.deeplearning(y= 'income',
training_frame = as.h2o(base_train),
hidden = c(50),
epochs = 100)
prev = h2o.predict(clas, newdata=as.h2o(base_test[, -15]))
prev = prev$predict
prev = as.vector(prev)
#------------- Confusion Matrix
conf_matrix = table(base_test[,15], prev)
conf_matrix
confusionMatrix(conf_matrix)
clas = h2o.deeplearning(y= 'income',
training_frame = as.h2o(base_train),
hidden = c(9),
epochs = 1000)
prev = h2o.predict(clas, newdata=as.h2o(base_test[, -15]))
prev = prev$predict
prev = as.vector(prev)
#------------- Confusion Matrix
conf_matrix = table(base_test[,15], prev)
conf_matrix
confusionMatrix(conf_matrix)
0.2*5+2*0.5+1*0.1
h2o.weights
h2o.weights()
weights1 <- h2o.weights(clas,matrix_id=1)
clas = h2o.deeplearning(y= 'income',
training_frame = as.h2o(base_train),
hidden = c(9),
epochs = 1000,
export_weights_and_biases=TRUE)
prev = h2o.predict(clas, newdata=as.h2o(base_test[, -15]))
prev = prev$predict
prev = as.vector(prev)
weights1 <- h2o.weights(clas,matrix_id=1)
View(weights1)
ll2 <- h2o.logloss(h2o.performance(clas,base))
ll2 <- h2o.logloss(h2o.performance(clas,as.h2o(base))
ll2 <- h2o.logloss(h2o.performance(clas,as.h2o(base)))
ll2 <- h2o.logloss(h2o.performance(clas,as.h2o(base)))
ll2 <- h2o.logloss(h2o.performance(clas,as.h2o(base_test)))
ll2
confusionMatrix(conf_matrix)
